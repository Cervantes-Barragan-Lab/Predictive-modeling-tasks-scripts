{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing/Importing Python Libraries"
      ],
      "metadata": {
        "id": "d7LL-3wWu87y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ3_0lASuxfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb550f7-2753-408d-c3ba-c7aca3d99db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-faffed60f9c3>:20: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('pdf', 'svg')\n"
          ]
        }
      ],
      "source": [
        "# 1. Install the necessary libraries if you don't have them\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install sklearn\n",
        "# !pip install matplotlib\n",
        "\n",
        "# 2. Import the packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# 3. Import specific modules from the libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from IPython.display import set_matplotlib_formats\n",
        "\n",
        "# 4.\n",
        "set_matplotlib_formats('pdf', 'svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Function"
      ],
      "metadata": {
        "id": "FHvLBJNThnyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomForestRegressionModel(dataset, target_variable, test_prop, min_ntrees,\n",
        "                                max_ntrees, cv_folds):\n",
        "  ## Inputs\n",
        "  # 1. dataset: pandas DataFrame - dataset with predictor vars and output\n",
        "  # 2. target_variable: character string - name of the output variable\n",
        "  # 3. test_prop: float - proportion of the data to be used for testing\n",
        "  # 4. min_ntrees: int - minimum number of trees to consider in the CV procedure\n",
        "  # 5. max_ntrees: int - maximum number of trees to consider in the CV procedure\n",
        "  # 6. cv_folds: int - number of folds to use in the CV procedure\n",
        "\n",
        "  ## Outputs\n",
        "  # 1. best_num_trees: int - optimal number of trees selected by the CV process\n",
        "  # 2. mean_test_scores: list - mean cross-validated scores for each tree number\n",
        "  # 3. mse_test: float - the mean squared error from the test set\n",
        "  # 4. y_pred_tes: list - the optimal RFR model predicted y-values for the test set\n",
        "  # 5. sorted_importances: list - feature importances sorted in descending order\n",
        "  # 6. final_model: trained RFR model using the optimal number of trees\n",
        "  # 7. X_train - pandas DataFrame - training set created w/ only predictors\n",
        "  # 8. X_test - pandas DataFrame - testing set created w/ only predictors\n",
        "  # 9. y_train - pandas DataFrame - outputs of training observations\n",
        "  # 10. y_test - pandas DataFrame - outputs of test observations\n",
        "\n",
        "  # 0. Make warnings\n",
        "\n",
        "  # i. Warning if there are NAs in your dataset\n",
        "  if dataset.isnull().values.any():\n",
        "        warnings.warn(\"WARNING: Your dataset contains observations with missing variable values (NAs). \"\n",
        "                      \"Consider handling missing values before proceeding with the analysis. \"\n",
        "                      \"You can use the pandas 'fillna()' function to fill missing values with a specific value \"\n",
        "                      \"or the 'dropna()' function to remove rows with missing values\")\n",
        "        return\n",
        "\n",
        "  # ii. Warning if there are categorical variables that are not dummied out\n",
        "  categorical_columns = dataset.select_dtypes(include='object').columns\n",
        "  if len(categorical_columns) > 0:\n",
        "    warnings.warn(\"WARNING: Your dataset contains columns with categorical variables that are not dummied out. \"\n",
        "    \"Consider applying one-hot encoding or other suitable encoding techniques to handle categorical variables.\")\n",
        "\n",
        "    return\n",
        "\n",
        "  # 1. Prepare your data and specificy predictor variables and output variable\n",
        "  X = dataset.drop(target_variable, axis = 1)\n",
        "  y = dataset[target_variable]\n",
        "\n",
        "  # 2. Split the data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                      test_size= test_prop,\n",
        "                                                      random_state=42)\n",
        "\n",
        "  # 3. Perform cross-validation to find the optimal number of trees\n",
        "\n",
        "  # i. Create a \"grid\" specifying the number of trees to test\n",
        "  param_grid = {'n_estimators': range(min_ntrees, max_ntrees)}\n",
        "\n",
        "  # ii. Create the RFR model object that will be cross-validated on diff # trees\n",
        "  rf_model_cv = RandomForestRegressor()\n",
        "\n",
        "  # iii. With your RFR model, test every number of trees in the grid via CV\n",
        "  grid_cv = GridSearchCV(rf_model_cv, param_grid= param_grid, cv=cv_folds)\n",
        "  grid_cv.fit(X_train, y_train)\n",
        "\n",
        "  # iv. Retrieve the cross-validated results\n",
        "  cv_results = grid_cv.cv_results_\n",
        "  mean_test_scores = cv_results['mean_test_score']\n",
        "  std_test_scores = cv_results['std_test_score']\n",
        "  num_trees = param_grid['n_estimators']\n",
        "\n",
        "  # v. Plot the number of trees vs. cross-validation error\n",
        "  plt.errorbar(num_trees, mean_test_scores, yerr= std_test_scores, marker='o',\n",
        "             color = 'red', ecolor = 'blue', capsize = 3)\n",
        "  plt.xlabel('Number of Trees')\n",
        "  plt.ylabel('GridSearchCV CV Error Metric')\n",
        "  plt.title('Number of Trees vs. Cross-Validated Error')\n",
        "  plt.grid(True)\n",
        "  plt.savefig('Cross-Validation-Plot.pdf',dpi = 500) # save pdf of plot\n",
        "  plt.show()\n",
        "\n",
        "  # vi. Retrieve the best model\n",
        "  best_model = grid_cv.best_estimator_\n",
        "  best_num_trees = grid_cv.best_params_['n_estimators']\n",
        "  print(\"Best number of trees:\", best_num_trees)\n",
        "\n",
        "  # 5. Plot variable importance\n",
        "\n",
        "  # i. Train the final model with the optimal number of trees\n",
        "  final_model = RandomForestRegressor(n_estimators=best_num_trees)\n",
        "  final_model.fit(X_train, y_train)\n",
        "\n",
        "  # ii. Get the feature importances\n",
        "  importances = final_model.feature_importances_\n",
        "\n",
        "  # iii. Sort the feature importances in descending order\n",
        "  sorted_indices = np.argsort(importances)[::-1]\n",
        "  sorted_importances = importances[sorted_indices]\n",
        "  sorted_features = X.columns[sorted_indices]\n",
        "\n",
        "  # iv. Plot the variable importance\n",
        "  color_palette = plt.cm.tab20.colors\n",
        "  plt.barh(range(len(sorted_importances)), sorted_importances, align='center',\n",
        "           color=color_palette[:len(sorted_importances)])\n",
        "  plt.yticks(range(len(sorted_importances)), sorted_features)\n",
        "  plt.xlabel('Feature Importance')\n",
        "  plt.ylabel('Features')\n",
        "  plt.title('Variable Importance')\n",
        "  plt.savefig('Variable-Importance-Plot.pdf', dpi = 500) # save pdf of plot\n",
        "  plt.show()\n",
        "\n",
        "  # 6. Test the final model on the test set and calculate MSE\n",
        "  y_pred_test = final_model.predict(X_test)\n",
        "  rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "\n",
        "  return best_num_trees, mean_test_scores, rmse_test, y_pred_test, sorted_importances, final_model, X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "BCtp4rDThpz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Your Data"
      ],
      "metadata": {
        "id": "QTmPqO9wh1WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "jrQIiGzlh4FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['filename.csv']))"
      ],
      "metadata": {
        "id": "1xNXM0LOiL4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Model and Visualizing Outputs"
      ],
      "metadata": {
        "id": "89Ib7RxbiXZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Loading dataset from pydataset and dropping NA observations\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "# 2. Specifying target variable I aim to predict\n",
        "target_variable = 'target_variable'\n",
        "\n",
        "# 3. Specifying the proportion of my dataset observations to test model on\n",
        "test_prop = .25\n",
        "\n",
        "# 4. Specifying the minimum number of trees to test\n",
        "min_ntrees = 5\n",
        "\n",
        "# 5. Specifying the maximum number of trees to test\n",
        "max_ntrees = 120\n",
        "\n",
        "# 5. Specifying the number of folds to use for cross-validation\n",
        "cv_folds = 10\n",
        "\n",
        "# 6. Running function and saving outputs into variables\n",
        "best_num_trees, mean_test_scores, rmse_test, y_pred_test, sorted_importances, final_model,X_train, X_test, y_train, y_test = RandomForestRegressionModel(dataset, target_variable, test_prop, min_ntrees,\n",
        "                                max_ntrees, cv_folds)"
      ],
      "metadata": {
        "id": "_o6sDaHgibRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prints the optimal tree number\n",
        "print(\"Best number of trees:\", best_num_trees)\n",
        "\n",
        "# 2. Prints list of CV errors associated with each tree number tested in CV\n",
        "print(\"Mean test scores:\", mean_test_scores)\n",
        "\n",
        "# 3. Prints list of the final model's predicted values for the test set obs\n",
        "print(\"RFR Model Predicted Test Set Outputs:\", y_pred_test)\n",
        "\n",
        "# 4. Prints the square root of the MSE from testing the model on the test set\n",
        "print(\"Square Root of Mean Squared Error (Test Set):\", rmse_test)\n",
        "\n",
        "# 5. Prints variable importances in descending order\n",
        "print(\"Sorted importances:\", sorted_importances)\n",
        "\n",
        "# 6. Pints the final model object\n",
        "print(\"Final model:\", final_model)"
      ],
      "metadata": {
        "id": "vUFQb3yIiuOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}